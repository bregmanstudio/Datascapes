{
 "metadata": {
  "name": "",
  "signature": "sha256:419071cd0cdb45639a6b04ec023d2f1f267ab5e8dd6b04682d8ff3871f5f6914"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pandas as pd\n",
      "from pylab import *\n",
      "from bregman.suite import *\n",
      "%matplotlib inline\n",
      "rcParams['figure.figsize'] = (10.0, 8.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Using Sound to Explore Data\n",
      "## Loading the Example Sounds\n",
      "This homework includes sound examples for you to try. Loading a sound file requires specifying its path and filename. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the path to an audio file\n",
      "# In this case, the sound was generated from helioseismology data from our sun \n",
      "# The sound depicts the resonant modes of the sun's ringing.\n",
      "# The data has been vastly sped up from hours or days per cycle to fractions of seconds, by setting the sample rate to 44100Hz \n",
      "audio_file = os.path.join(\"sounds\",\"three_modes.wav\")\n",
      "print audio_file\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Playing and viewing audio files\n",
      "\n",
      "The BregmanToolkit has a built-in `play()` function for listening to audio data.\n",
      "Use the `balance_signal()` function to normalize the audio to allowable `(-1.0, 1.0)` range.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load and play the audio data\n",
      "snd,sr,fmt = wavread(audio_file) # load the audio file, giving the data (snd), sample rate (sr) and format\n",
      "print \"sr=\",sr\n",
      "print \"snd.shape:\", snd.shape, \"time:\",len(snd)/sr,\"secs\"  # print the audio data's array size\n",
      "print \"root mean square:\", sqrt(abs(snd**2).mean()) # root mean square \n",
      "print \"snd.min(), snd.max()\", snd.min(), \",\", snd.max()\n",
      "sys.stdout.flush() # print info before continuing\n",
      "\n",
      "play(snd,sr) # play it\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Play sound at a much slower rate, sr/4, which scales frequency content down by a factor of 4 \n",
      "play(snd[:len(snd)/4],sr/4) # truncate sound to 1/4 duration, otherwise will last 4 x longer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Play sound at a much faster rate, 4x, which scales frequency content up by a factor of 4 \n",
      "play(snd,sr*4) # sound is a quarter original duration (played 4 x faster)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the first 0.25s of the audio\n",
      "plot(arange(0.25*sr)/sr, snd[:0.25*sr])\n",
      "title('Sun: Helioseismic Time Series Data')\n",
      "xlabel('Time (s)')\n",
      "ylabel('Amplitude')\n",
      "grid()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the first 0.01s of the audio\n",
      "plot(arange(0.01*sr)/sr, snd[:0.01*sr])\n",
      "title('Sun: Helioseismic Time Series Data')\n",
      "xlabel('Time (s)')\n",
      "ylabel('Amplitude')\n",
      "grid()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Extracting and Plotting Features: The Spectrum\n",
      "\n",
      "The spectrum of a time series (such as sound data) is a very useful way of inspecting data. The spectrum consists of samples of the frequency content (how much energy there is in the data for a range of frequencies) over time, hence it is two dimensional. \n",
      "\n",
      "We are generally interested in the magnitude spectrum (often denoted by `spec.X`), there is also the phase spectrum. We can extract the full complex spectrum (magnitude and phase) using the short-time Fourier transform (`spec.STFT`).\n",
      "\n",
      "The following introductory example shows how: \n",
      "    - assign to a variable `linspec` the spectrogram of an audio file ( the Short-Time Fourier Transform (STFT) )\n",
      "    - specify STFT window parameters N,W, and H \n",
      "    - plot the result as a time-frequency image.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Short-time Fourier transform\n",
      "linspec = LinearFrequencySpectrum(audio_file, nfft=1024, wfft=512, nhop=256) # nfft=fft window, wfft=audio window, hop=skip size\n",
      "linspec.feature_plot(normalize=True,dbscale=True) # plot by first scaling the data to full range decibels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Looking at the time-average of the spectrum is often informative,\n",
      "# this is the view of the average spectrum taken over all time samples \n",
      "plot(linspec._fftfrqs, 20*log10(linspec.X.mean(1))) # x-axis is frequency, y-axis is power in dB\n",
      "axis('tight');grid() # Make the plot fit the image, tightly\n",
      "title('Average Spectrum of Time Series (log Power)')\n",
      "xlabel('Frequency (Hz)')\n",
      "ylabel('Power (dB)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Built-in Help on modules, objects, and their methods\n",
      "\n",
      "All BregmanToolkit objects are fully self documenting. \n",
      "\n",
      "`help(object)`\n",
      "\n",
      "Here, we'll access help on the spectrum object's feature_plot method,"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(linspec.feature_plot)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Audio Feature Synthesis, Using the Spectrum to Sonify Data\n",
      "Bregman's Features class can synthesize audio from feature parameters. First, we use the Short-Time Fourier Transform to create a spectrogram. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Short-Time Fourier Transform (STFT)\n",
      "# Use phase-vocoder optimal 4:2:1 pattern for N, W, and H FFT parameters\n",
      "linspec = LinearFrequencySpectrum(audio_file, nfft=4096, wfft=2048, nhop=1024)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Feature Time-Stretch / Expand (using the Phase Vocoder method)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Varispeed playback at 1/4 speed, also truncate generated audio to 1/3 length for brevity  \n",
      "# We achieve this by inverting the short-time Fourier transform using Feature.inverse() method\n",
      "# NOTE: rate of spectrum slices in time has changed, only the phases are modified\n",
      "x_hat = linspec.inverse(pvoc=0.25) # invert features 1/4 speed using a phase vocoder with windowing\n",
      "x_len = len(x_hat) // 3  # double slash means perform integer division (truncate decimals).\n",
      "play(balance_signal(x_hat[:x_len]),sr) # play 1/3 of the audio generated by inverse(pvoc=0.25) above"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Varispeed playback at 4 x speed  \n",
      "# We achieve this by inverting the short-time Fourier transform using Feature.inverse() method\n",
      "# NOTE: rate of spectrum slices in time has changed, only the phases are modified\n",
      "x_hat = linspec.inverse(pvoc=4.0) # invert features 4 x speed using a phase vocoder with windowing\n",
      "x_len = len(x_hat)  # double slash means perform integer division (truncate decimals).\n",
      "play(balance_signal(x_hat),sr) # play audio generated by inverse(pvoc=0.25) above"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using the Inverse Fourier Transform to Sonify Image Data\n",
      "\n",
      "Here we will load an image and use the image data as STFT coefficients via LinearFrequencySpectrum, invert the spectrum to sonify the image.\n",
      "\n",
      "Setting Fourier transform coefficients with data, and using the inverse() method, yields sonifications of images. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Image # Use Python's image library"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "im = Image.open(\"SDSS_1600.jpg\") # Load the provided SDSS data, on the large-scale structure of the universe\n",
      "imshow(im) # we can display 2D data as an image, just like we did with the Spectrum above\n",
      "print im.format, im.size, im.mode # inspect the dimensions and format of the image\n",
      "title('Spatial Galaxy Density v Redshift (Distance), source: SDSS')\n",
      "xlabel('Image X')\n",
      "ylabel('Image Y')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert Image to Grayscale in the range [0.0,1.0]\n",
      "data = array(im.getdata()) / 255.\n",
      "data = data.reshape(im.size[1],im.size[0],3) # imWidth x imHeight x 3 RGB channels\n",
      "imshow(data.mean(2), cmap=cm.gray)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make a LinearFrequencySpectrum that will have the correct dimensions for the given image\n",
      "def image_to_spectrum(data, ny=None,**kwargs):\n",
      "    if len(data.shape)==3:\n",
      "        data = data.copy()\n",
      "        data = data.mean(2)\n",
      "    imHeight, imWidth = data.shape\n",
      "    nF = int(2**(ceil(log2(imHeight))+1)) # Make the spectrum size at least double the image height\n",
      "    nsamps = int(ceil(imWidth * nF/4)) # Calculate number of imWidth frames x nF/4\n",
      "    print nF, nsamps, nsamps/(nF/4)\n",
      "    spec = LinearFrequencySpectrum(randn(nsamps), nfft=nF, wfft=nF/2, nhop=nF/4, **kwargs)\n",
      "    spec.STFT[:imHeight,:imWidth] = data * exp(-1j*angle(spec.STFT[:imHeight,:imWidth]))\n",
      "    spec.X[:imHeight,:imWidth] = data\n",
      "    return spec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now we can convert an image to a spectrum, and invert the spectrum to audio\n",
      "# This method is a form of additive synthesis, but using localized windowed 'grains' of sound scattered in Freq and Time. \n",
      "# It is called granular synthesis.\n",
      "spec = image_to_spectrum(data)\n",
      "spec.feature_plot(normalize=True, cmap=cm.gray)\n",
      "snd = spec.inverse()\n",
      "show()\n",
      "play(balance_signal(snd))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Covenience function to mask RGB color channels\n",
      "def extract_color(data, n):\n",
      "    channels = data.copy()\n",
      "    for ch in range(channels.shape[2]):\n",
      "        if ch != n:\n",
      "            channels[:,:,ch] = channels[:,:,ch] * 0 \n",
      "    return channels\n",
      "\n",
      "subplot(221); imshow(extract_color(data, 0)); title('R')\n",
      "subplot(222); imshow(extract_color(data, 1)); title('G')\n",
      "subplot(223); imshow(extract_color(data, 2)); title('B')\n",
      "subplot(224); imshow(data); title('RGB')\n",
      "show()\n",
      "\n",
      "print \"RED\"\n",
      "universe_spec_r = image_to_spectrum(extract_color(data, 0))\n",
      "r_hat = universe_spec_r.inverse()\n",
      "play(balance_signal(r_hat))\n",
      "\n",
      "print \"GREEN\"\n",
      "universe_spec_g = image_to_spectrum(extract_color(data, 1))\n",
      "g_hat = universe_spec_g.inverse()\n",
      "play(balance_signal(g_hat))\n",
      "\n",
      "print \"BLUE\"\n",
      "universe_spec_b = image_to_spectrum(extract_color(data, 2))\n",
      "b_hat = universe_spec_b.inverse()\n",
      "play(balance_signal(b_hat))\n",
      "\n",
      "print \"RGB\"\n",
      "play(balance_signal(r_hat+g_hat+b_hat))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Log Frequency Axis, LogFrequencySpectrum\n",
      "\n",
      "We can repeat the same operation as above, using a logarithmic frequency axis, which closer represents human perception of spectrum frequencies than linear frequency scaling.\n",
      "\n",
      "The frequencies bands are now spaced increasingly further apart, with most of the information concentrated in the low frequency spectrum, and progressively less information about higher frequencies (as with our ears).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extract a Log-frequency spectrum, specifying windowing parameters\"\n",
      "logspec = LogFrequencySpectrum(audio_file, nhop=2205) # extract log spectrum\n",
      "logspec.feature_plot(dbscale=True, cmap=cm.gray) # plot features on dB scale\n",
      "title('Narrow-band Log Spectrum')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just as with the Linear spectrum, we can invert the log spectrum using the feature inverse() method\"\n",
      "x_hat = logspec.inverse() # invert phaseless features to audio\n",
      "play(balance_signal(x_hat)) # play inverted features\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using the Inverse Log Frequency Spectrum to Sonify Image Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make a LogFrequencySpectrum that will have the correct dimensions for the given image\n",
      "def image_to_logspectrum(data, **kwargs):\n",
      "    if len(data.shape)==3:\n",
      "        data = data.copy()\n",
      "        data = data.mean(2)\n",
      "    imHeight, imWidth = data.shape\n",
      "    nF = kwargs.pop('nfft',2048)\n",
      "    nB = kwargs.pop('nbpo',int(ceil(imHeight//7))) # Make the bands per octave the image height / 7 octaves\n",
      "    nsamps = int(ceil(imWidth * nF/4)) # Calculate  \n",
      "    print nF, nsamps, nsamps/(nF/4)\n",
      "    spec = LogFrequencySpectrum(randn(nsamps), nfft=nF, wfft=nF/2, nhop=nF/4, nbpo=nB, **kwargs)\n",
      "    spec.STFT[:imHeight,:imWidth] = data * exp(-1j*angle(spec.STFT[:imHeight,:imWidth]))\n",
      "    spec.X[:imHeight,:imWidth] = data\n",
      "    return spec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# By using a longer FFT window, we generate more samples in time\n",
      "spec = image_to_logspectrum(data, nfft=4096)\n",
      "spec.feature_plot(normalize=True, cmap=cm.gray)\n",
      "snd = spec.inverse()\n",
      "show()\n",
      "play(balance_signal(snd))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List the (default) parameters that control feature extraction.\n",
      "# Use any parameter as a keyword argument to a feature extractor.\n",
      "# Or use a parameter dict {'key1':value1, ...} with the base Feature class\n",
      "\n",
      "p = Features.default_params() # inspect default parameters\n",
      "for parameter in p: print parameter+': ', p[parameter] # show feature extraction parameter dict\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## List of BregmanToolkit tutorials"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "tuts = get_tutorials()\n",
      "for tutorial in tuts: print tutorial"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "print \"\\nBREGMAN>Next, use built-in help to view the pydoc help for the features module\"\n",
      "\n",
      "help(features) # see help on the features module \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}