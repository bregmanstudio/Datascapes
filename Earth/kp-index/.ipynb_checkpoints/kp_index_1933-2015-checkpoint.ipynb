{
 "metadata": {
  "name": "",
  "signature": "sha256:035cef1c05cf8b3f93e11454e597b0401bcb14783315fb21f9fb01893d2384bd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>MUS103 / MUS14.02: Datascapes</h1>\n",
      "<h2>Dartmouth College (Prof. Casey and Prof. Casas)</h2>\n",
      "\n",
      "<h1>Week 1: Beginning Data Exploration: Earth's Magnetic Field, KP-Index Data</h1>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this short assignment you will:\n",
      "- Load and Parse Earth's Magnetic Field data \n",
      "- Filter the data by date and time \n",
      "- Plot a range of different *views* of the data\n",
      "- Sonify the data as raw audio and as a musical interpretation "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from pylab import *\n",
      "from bregman.suite import *\n",
      "\n",
      "%matplotlib inline\n",
      "rcParams['figure.figsize'] = (10.0, 8.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Time Series with Date-and-Time Index</h1>\n",
      "\n",
      "We will be using KP-Index data from [NASA's Space Physics Interactive Data Resource (SPIDR)](http://spidr.ngdc.noaa.gov/spidr/). The first step in working with data is to load it and parse it into a table or array. Parsing is the process of interpreting the text or numbers in a file on disk into a structured data type.\n",
      "\n",
      "In this notebook we will use the `pandas` parser `pd.read_csv()` method to load a data file in the current directory named `spidr_1451721279326_0.txt`. Prior to parsing, we usually inspect such text files using a text editor or a terminal to see where the data begins, and how the data values are separated. Those clues tell us how we should parse the data.\n",
      "\n",
      "In our kp-index text data file, the first 15 rows are *metadata*, or information about the data, such as when it was generated, a short description, the sampling interval used in collecting the data, and where it came from. We want the parser to skip these first 15 rows, as they do not contain the actual data. \n",
      "\n",
      "After the first 15 rows, the data is organized in rows with 3 columns separated by spaces. The 16th row in the text file provides text headings for each column, which the parser will use to label the data for us. The data are separated by spaces, `sep=' '`, we should skip any additional spaces `skipinitialspace=True` and we want the index for the data to consist of the date and time which are columns 0 and 1 of the data respectively (row, column indexing begins at 0 and ends at N-1 in most computer languages, with N being the number of data points).\n",
      "\n",
      "Finally, we tell the parser that we are only interested in the first three columns, `usecols=[0,1,2]`, and that we want the information in the first column, 0, to be the row index for the   parsed data, `index_col=[0]`. Supplying a list of *arguments* to the function `pd.read_csv()` achieves all of the interpretation that we need to begin working with the data.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Python comments begin with '#' and are ignored by the interpreter\n",
      "# Here we load the kp-index data into a pandas DataFrame structure\n",
      "res = pd.read_csv('spidr_1451721279326_0.txt', sep=' ', skiprows=15, skipinitialspace=True, parse_dates={'datetime': [0, 1]}, usecols=[0,1,2], index_col=[0]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inspect the types of the data\n",
      "print \"Data types:\" \n",
      "print res.dtypes \n",
      "\n",
      "# Output to the current cell the first 10 rows of the data (Pandas formats output nicely)\n",
      "# Pandas uses Python's list slice notation for data access [start:end:skip]\n",
      "res[:10] # Note that we can use integers to index the rows. \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# res.index holds the dates and times for each row, we can use that for logical indexing\n",
      "# using comparison operators such as ==(equal), !=(not equal), >, <, >=, <=, &(and), |(or) \n",
      "# E.g. output all data with date and time greater than or equal to midnight on June 30th 2015.\n",
      "# Note that the order of he index is from largest to smallest time: YYYY-MM-DD hh:mm:ss\n",
      "res[res.index>='2015-06-30 00:00:00']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pandas DataFrame objects provide analytics about the data that they contain.\n",
      "# Use the describe() method to get an overview of the data's statistics.\n",
      "res.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can use our date-time index to plot a range of specific dates. \n",
      "# Here we use Python's slice notation to specify a range from '2014-06-01' to '2015-06-01'\n",
      "try: # (This try-except block helps avoid an annoying bug in plotting with date-time indexing)\n",
      "    res['2014-06-01':'2015-06-01'].plot() \n",
      "except:\n",
      "    pass\n",
      "title('kp-Index 2014-06-01 to 2015-06-01 3-hour',fontsize=20)\n",
      "ylabel('kp-index',fontsize=16)\n",
      "grid()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can use Python's numerical (numpy) tools for data processing\n",
      "# Here, we obtain the 'value' field of the data as a numpy array\n",
      "# Then we can use unique() and hist() to get a list of all unique data values (29 of them)\n",
      "# and to show us how they are distributed (looks like a chi^2 distribution to me)\n",
      "# We also see that the data is arranged approximately in 1/3rds. With an anomaly at 0.1\n",
      "# This annomaly can be clearly seen in the histogram below (there is a gap at 0.1) which\n",
      "# means that there is hardly any data with the value 0.1 (2 rows of 241048 have value 0.1)\n",
      "raw_data = res['value'].get_values()\n",
      "\n",
      "# Look at some statistics\n",
      "print \"Total values={},  unique value count={}\".format(len(raw_data), len(unique(raw_data))) \n",
      "print \"mean={:.3f}, std={:.3f}\".format(raw_data.mean(), raw_data.std()) \n",
      "# Show unique values\n",
      "print \"unique values={}\".format(unique(raw_data)) \n",
      "\n",
      "# Make a histogram\n",
      "h = hist(raw_data, unique(raw_data))\n",
      "title('kp-Index histogram of unique values',fontsize=20)\n",
      "xlabel('Value',fontsize=16)\n",
      "ylabel('Frequency', fontsize=16)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Statitics, such as the mean and standard deviation, are very useful ways to inspect data\n",
      "# Our pandas DataFrame object (res) has mean() and std() methods\n",
      "# We can filter the data by date-time index, useful for generating alternative views of the data\n",
      "# Here, we look at the mean and standard error of the data by hour-of-day instead of as a raw time series\n",
      "\n",
      "hours = unique(res.index.hour)\n",
      "m = [res[res.index.hour==t].mean() for t in hours] # Python's list comprehension notation\n",
      "e = [res[res.index.hour==t].std() / sqrt(sum(res.index.hour==t)) for t in hours] # ste = std / sqrt(N)\n",
      "errorbar(arange(len(hours)), m, e)\n",
      "title('Mean kp-Index 1933-2015 by Hour of Day',fontsize=20)\n",
      "grid()\n",
      "xticks(arange(len(hours)), hours)\n",
      "xlabel('Hour of Day', fontsize=14)\n",
      "ylabel('Mean KP-Index (+/- Standard Error', fontsize=14)\n",
      "axis('tight')\n",
      "ax=axis()\n",
      "ax=axis(xmin=ax[0]-0.5, xmax=ax[1]+0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here we will inspect the data by day of the month.\n",
      "# The large error bars tell us that there is not a strong pattern in this view of the data\n",
      "days = unique(res.index.day)\n",
      "m = [res[res.index.day==t].mean() for t in days]\n",
      "e = [res[res.index.day==t].std() / sqrt(sum(res.index.day==t)) for t in days]\n",
      "errorbar(arange(len(m))+1, m, e)\n",
      "title('Mean kp-Index 1933-2015 by Day of Month',fontsize=20)\n",
      "grid()\n",
      "axis('tight')\n",
      "ax=axis()\n",
      "ax=axis(xmin=ax[0]-0.5, xmax=ax[1]+0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here, we inspect the data by month of the year\n",
      "# The smaller error bars tell us that there IS a pattern here\n",
      "# Look at the months and see if you can understand the pattern\n",
      "months = unique(res.index.month)\n",
      "m = [res[res.index.month==t].mean() for t in months]\n",
      "e = [res[res.index.month==t].std() / sqrt(sum(res.index.month==t)) for t in months]\n",
      "errorbar(arange(len(months)), m, e)\n",
      "title('Mean kp-Index 1933-2015 by Month of Year',fontsize=20)\n",
      "xticks(arange(len(months)),months)\n",
      "grid()\n",
      "axis('tight')\n",
      "ax=axis()\n",
      "ax=axis(xmin=ax[0]-0.5, xmax=ax[1]+0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Spectrum: The Frequency Content of a Time Series</h1>\n",
      "The spectrum of a time series (such as the kp-index) tells us about its frequency content.\n",
      "That is, the magnitude (and phase) of each frequency component in the time series\n",
      "\n",
      "Note: REQUIRES the [Bregman Toolkit](https://github.com/bregmanstudio/BregmanToolkit)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here, we use the short-time Fourier transform (STFT) to inspect frequency content over time\n",
      "# The horizontal striations indicate to us that there is periodic (harmonic) structure in the data\n",
      "SR = int(round(365.25 * 8)) # 1 second = 1 year\n",
      "N = SR # 1 window per year, hop year/4\n",
      "raw_data = res['value'].get_values()\n",
      "S = LinearFrequencySpectrum(raw_data-raw_data.mean(), nfft=N, wfft=N//2, nhop=N//4, sample_rate=SR)\n",
      "print S.STFT.shape\n",
      "S.feature_plot(dbscale=1)\n",
      "title('kp-Index years 1933-2015 |STFT| N={}, H={}'.format(S.nfft,S.nhop), fontsize=20 )\n",
      "xlabel('Time (years)',fontsize=16)\n",
      "ylabel('Frequency (Hz)',fontsize=16)\n",
      "# Detail\n",
      "figure()\n",
      "feature_plot(abs(S.STFT)[:N//10,:],dbscale=1)\n",
      "title('DETAIL: kp-Index years 1933-2015 |STFT| N={}, H={}'.format(S.nfft,S.nhop), fontsize=20 )\n",
      "xlabel('Time (years)',fontsize=16)\n",
      "ylabel('Frequency (Hz)',fontsize=16)\n",
      "x=xticks(arange(0,S.X.shape[1],S.X.shape[1]/16), (arange(0,S.X.shape[1],S.X.shape[1]/16) * S.nhop / S.nfft).round(2))\n",
      "y=yticks(arange(0,N//10,N//50), (S._fftfrqs[arange(0,N//10,N//50)]).round(2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# An alternative view of the spectrum is to look at the long-term average of the spectrum\n",
      "# This shows us the distribution of energy in the data over frequency, and any prominant periodicities.\n",
      "# By inspecting the plot, we see that there are periodicities at 365Hz (day) and 13Hz (lunar months?)\n",
      "# (I know, Hz isn't the correct time unit really. But I set this up so that 1 year = 1 second, you see?)\n",
      "# Notice that there are also harmonics of the prominant periodicities. This is because these periodicities\n",
      "# are not purely sinusoidal (sine waves), hence they have harmonics.\n",
      "\n",
      "mX = abs(S.X).mean(1)\n",
      "semilogy(mX)\n",
      "axis('tight')\n",
      "title('kp-Index 1933-2015 3-hour Mean |STFT|',fontsize=20)\n",
      "grid()\n",
      "x=xticks(arange(0,len(mX),len(mX)//10), ((S._fftfrqs)[arange(0,len(mX),len(mX)//10)]).round(2), rotation=-90)\n",
      "# Plot the low-frequency details\n",
      "mXlf = mX[:500]\n",
      "figure()\n",
      "semilogy(mXlf)\n",
      "axis('tight')\n",
      "title('DETAIL: kp-Index 1933-2015 3-hour Mean |STFT|',fontsize=20)\n",
      "grid()\n",
      "x=xticks(arange(0,len(mXlf),10), ((S._fftfrqs)[arange(0,len(mXlf),10)]).round(3), rotation=-90)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Sonification I (raw data to audio)</h1>\n",
      "\n",
      "Note: Requires the [Bregman Toolkit](http://github.com/bregmanstudio/BregmanToolkit)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here, we listen to the raw data as audio. We can hear the periodic components of in the data\n",
      "# as 'pitches', as well as hearing the overall energy distribution over frequency.\n",
      "# The data sounds noisy, because nature and measurement are inherently noisy.\n",
      "sr = 44100\n",
      "raw_data = res['value'].get_values()\n",
      "raw_data = raw_data - raw_data.mean()\n",
      "play(balance_signal(raw_data), sr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = sinusoid(f0=sr/2/(365.25/28.), num_points=len(raw_data),sample_rate=sr) # lunar cycles\n",
      "play(balance_signal(x), sr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "play(c_[balance_signal(raw_data), balance_signal(x)].T, sr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Sonification II (raw data to pitches)</h1>\n",
      "Note: Requires the [Bregman Toolkit](http://github.com/bregmanstudio/BregmanToolkit)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here we MAP the data using the Major musical scale (frequency ratios of 2**([0,2,4,5,7,9,11]/12.)\n",
      "# We create multiple voices by re-sampling the data by Year, Month, Week, and Day\n",
      "# The different time scales are kept relative to each other, so that they remain in temporal proportion\n",
      "# Finally, we synthesize the major-scale mapped data using a simple additive synthesizer with 10 harmonics\n",
      "\n",
      "\n",
      "# Resample to different time scales: month, year\n",
      "subplot(211)\n",
      "plot(repeat(res.resample('12m','mean')['value'].get_values(),12,0),linewidth=4)\n",
      "plot(res.resample('m','mean')['value'].get_values())\n",
      "axis('tight')\n",
      "title('kp-Index Month/Year Means',fontsize=16)\n",
      "g=grid()\n",
      "subplot(212)\n",
      "plot(repeat(res.resample('12m','median')['value'].get_values(),12,0),linewidth=4)\n",
      "plot(res.resample('m','median')['value'].get_values())\n",
      "axis('tight')\n",
      "title('kp-Index Month/Year Medians',fontsize=16)\n",
      "g=grid()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A simple computer music instrument (CMI)\n",
      "# The following functions and variables act as a mapping for the kp-index data\n",
      "# The mapping is from an integer (kp-index * 3) to musical scale degree\n",
      "# We can choose which musical scale to use by changing the mode lookup table\n",
      "\n",
      "epd = 8 # events per day\n",
      "evy = epd*365.25 # events per year\n",
      "ev_map = {'d':epd,'m':evy/12,'12m':evy,'w':epd*7} # events per time-period\n",
      "\n",
      "# Modal lookup tables (expressed in half-steps from the tonic)\n",
      "modes = {\n",
      "    'major': [0, 2, 4, 5, 7, 9, 11], # melody notes move step-wise\n",
      "    'major_bass': [0, 7, 2, 9, 4, 11, 5], # bass notes move by circle of fifths\n",
      "    'minor': [0, 2, 3, 5, 7, 8, 11], # harmonic minor key \n",
      "    'minor_bass': [0, 7, 2, 8, 3, 11, 5] # harmonic minor key bass (circle of fifths) \n",
      "}\n",
      "\n",
      "# The synthesizer, uses Bregman's harmonics() function to lookup an additive synth model\n",
      "def make_note(note, vol, dur, base_freq=440.0, **params):\n",
      "    params.setdefault('num_harmonics',10)\n",
      "    params.setdefault('sample_rate',44100) \n",
      "    params.setdefault('num_points', int(round(dur*params['sample_rate'])))\n",
      "    w = hanning(88)\n",
      "    wn = len(w) // 2.0\n",
      "    h = vol * harmonics(f0=base_freq*2**(note/12.0), **params) # \n",
      "    h[:wn] = h[:wn] * w[:wn]\n",
      "    h[-wn:] = h[-wn:] * w[-wn:]\n",
      "    return h\n",
      "\n",
      "# Perform the mapping from an integer scale degree to a modal interval\n",
      "def mode_map(n, mode=modes['major']):    \n",
      "    n = int(round(n)) \n",
      "    pc = n%len(mode)\n",
      "    octave = n//len(mode)\n",
      "    return mode[pc] + octave*12\n",
      "\n",
      "# Perform the resampling in time (by taking the mean or median) and map to musical scale\n",
      "def map_pitch(x, rule='12m', how='mean', mode=modes['major']):\n",
      "    x2 = x.resample(rule, how, closed='left')\n",
      "    for i, v in enumerate(x2['value']):\n",
      "        x2['value'][i] = mode_map(v, mode)\n",
      "    return x2\n",
      "\n",
      "# Perform the audio synthesis, returning an audio signal\n",
      "def synthesize(x, dur=1.0, f0=220.0, **params):\n",
      "    snd = [make_note(n, 1.0, dur, base_freq=f0, **params) for n in x['value']]\n",
      "    return balance_signal(hstack(snd))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Tonal music realization of multiple time-scales of the kp-index data\n",
      "# 4 part harmony: average the time series values by: day, week, month, year for each musical part\n",
      "# Make the year the bass note and the 'key' for scale lookup\n",
      "# Shift the day, week, and month parts to the key of the year\n",
      "# Play the tonic of the key (year) as the bass part \n",
      "res2 = res.copy() # copy the data, so that we can modify the copy without changing the original\n",
      "res2 *= 3 # map the value to an integer (remember, values were quantized into 1/3rds) \n",
      "y_notes = map_pitch(res2, '12m','median', modes['major_bass']) # resample at 12m (12month==1year) intervals\n",
      "for i, yr in enumerate(y_notes.index.year): # shift the other parts by the key of the year\n",
      "    yr_idx = '{}'.format(yr) # The index needs to be a string\n",
      "    res2.loc[yr_idx,'value'] =  res2.loc[yr_idx,'value'].add(y_notes.loc[yr_idx,'value'][0]%12)\n",
      "m_notes = map_pitch(res2, 'm','median', modes['major']) # resample and map to musical pitches by month\n",
      "w_notes = map_pitch(res2, 'w','median', modes['major']) # by week\n",
      "d_notes = map_pitch(res2, 'd','median', modes['major']) # by day"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(res2.loc[yr_idx,'value'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# From the musical pitch series generated above, synthesize actual audio\n",
      "y_snd = synthesize(y_notes, 4.0, 27.5, afun=lambda a: a) # bass: all 10 harmonics at full amplitude\n",
      "m_snd = synthesize(m_notes, 4.0*ev_map['m']/evy, 110.) # tenor: decaying 10 harmonics (default)\n",
      "w_snd = synthesize(w_notes, 4.0*ev_map['w']/evy, 440, num_harmonics=1) # alto: 1 harmonic (sine wave)\n",
      "d_snd = synthesize(d_notes, 4.0*ev_map['d']/evy, 1760, num_harmonics=1) # soprano: 1 harmonic (sine wave)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Truncate all signals to the same length (correction for minor differences due to resampling approximations)\n",
      "snd_lens = len(y_snd), len(m_snd), len(w_snd), len(d_snd)\n",
      "print snd_lens \n",
      "n = min(snd_lens)\n",
      "y_snd = y_snd[:n]\n",
      "m_snd = m_snd[:n]\n",
      "w_snd = w_snd[:n]\n",
      "d_snd = d_snd[:n]\n",
      "print \"nsamples = \", n, \"=\", round(n/44100.,2), \"secs.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Scale the audio signal to allowable ranges, balance the musical parts with decreasing amplitude from low-to-high pitch\n",
      "# Sit back and listen to the 82 years of kp-index expressed as 5 minutes of music\n",
      "amp = 4\n",
      "play(balance_signal(amp**y_snd + m_snd + (amp**-1)*w_snd + (amp**-2)*d_snd)) # weight amplitude decreasing with snd frequency"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Data Mapping Methods</h1>\n",
      "\n",
      "Data Wrangling  \n",
      "- Centering  \n",
      "- Normalization  \n",
      "- Quantization  \n",
      "- Derivatives\n",
      "- Resampling\n",
      "- Spectrum: Fourier transform, linear / log frequency, linear / log amplitude\n",
      "\n",
      "Audio\n",
      "- Sinusoidal synthesis: freq, amp, phase, partials, shepard tones  \n",
      "- Sample rate, Nyquist frequency, Resampling\n",
      "- Wavetable synthesis (map data to wavetable lookup rate)  \n",
      "- Waveshaping synthesis\n",
      "- Modulation: AM, FM, PM\n",
      "\n",
      "Musical Maps\n",
      "- Pitch\n",
      "- Scale, Degree, Modulation(Key), Mode(Rotation)\n",
      "- Rhythm and Meter\n",
      "- Harmony\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}